{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7358cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import time\n",
    "import json\n",
    "import sagemaker.amazon.common as smac\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"marcus-machine-failure\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a426cc8",
   "metadata": {},
   "source": [
    "## Load training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b549dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "\n",
    "s3 = s3fs.S3FileSystem(anon=False)\n",
    "\n",
    "key = \"ai4i2020_prep.csv\"\n",
    "with s3.open(f'{bucket}/{prefix}/{key}','r') as f:\n",
    "    feature_df = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e2385f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>process_temperature</th>\n",
       "      <th>rotational_speed</th>\n",
       "      <th>torque</th>\n",
       "      <th>tool_wear</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19317</th>\n",
       "      <td>1</td>\n",
       "      <td>0.565180</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.132712</td>\n",
       "      <td>0.578316</td>\n",
       "      <td>0.830040</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19318</th>\n",
       "      <td>1</td>\n",
       "      <td>0.338743</td>\n",
       "      <td>0.356003</td>\n",
       "      <td>0.878347</td>\n",
       "      <td>0.094848</td>\n",
       "      <td>0.335968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19319</th>\n",
       "      <td>1</td>\n",
       "      <td>0.462273</td>\n",
       "      <td>0.655407</td>\n",
       "      <td>0.319558</td>\n",
       "      <td>0.330801</td>\n",
       "      <td>0.873518</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19320</th>\n",
       "      <td>1</td>\n",
       "      <td>0.647715</td>\n",
       "      <td>0.594625</td>\n",
       "      <td>0.302678</td>\n",
       "      <td>0.366137</td>\n",
       "      <td>0.893281</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19321</th>\n",
       "      <td>1</td>\n",
       "      <td>0.730462</td>\n",
       "      <td>0.598804</td>\n",
       "      <td>0.116997</td>\n",
       "      <td>0.590625</td>\n",
       "      <td>0.280632</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y  air_temperature  process_temperature  rotational_speed    torque  \\\n",
       "19317  1         0.565180             0.518519          0.132712  0.578316   \n",
       "19318  1         0.338743             0.356003          0.878347  0.094848   \n",
       "19319  1         0.462273             0.655407          0.319558  0.330801   \n",
       "19320  1         0.647715             0.594625          0.302678  0.366137   \n",
       "19321  1         0.730462             0.598804          0.116997  0.590625   \n",
       "\n",
       "       tool_wear  high  low  medium  \n",
       "19317   0.830040     1    0       0  \n",
       "19318   0.335968     0    0       1  \n",
       "19319   0.873518     0    0       0  \n",
       "19320   0.893281     0    0       1  \n",
       "19321   0.280632     0    0       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0427f11e",
   "metadata": {},
   "source": [
    "Adapted from SageMaker example [Breast Cancer Prediction](https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_applying_machine_learning/breast_cancer_prediction/Breast%20Cancer%20Prediction.html) notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f619e8f",
   "metadata": {},
   "source": [
    "# Create Features and Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85478e4",
   "metadata": {},
   "source": [
    "## Split the data into 80% training, 10% validation and 10% testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80f6765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_split = np.random.rand(len(feature_df))\n",
    "train_list = rand_split < 0.8\n",
    "val_list = (rand_split >= 0.8) & (rand_split < 0.9)\n",
    "test_list = rand_split >= 0.9\n",
    "\n",
    "data_train = feature_df[train_list]\n",
    "data_val = feature_df[val_list]\n",
    "data_test = feature_df[test_list]\n",
    "\n",
    "train_y = ((data_train.iloc[:, 0] == 1) + 0).to_numpy()\n",
    "train_X = data_train.iloc[:, 1:].to_numpy()\n",
    "\n",
    "val_y = ((data_val.iloc[:, 0] == 1) + 0).to_numpy()\n",
    "val_X = data_val.iloc[:, 1:].to_numpy()\n",
    "\n",
    "test_y = ((data_test.iloc[:, 0] == 0) + 0).to_numpy()\n",
    "test_X = data_test.iloc[:, 1:].to_numpy();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1627af",
   "metadata": {},
   "source": [
    "Now, we’ll convert the datasets to the recordIO-wrapped protobuf format used by the Amazon SageMaker algorithms, and then upload this data to S3.   We’ll start with training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96956923",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"linear_train.data\"\n",
    "\n",
    "f = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(f, train_X.astype(\"float32\"), train_y.astype(\"float32\"))\n",
    "f.seek(0)\n",
    "\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"train\", train_file)\n",
    ").upload_fileobj(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3796b78a",
   "metadata": {},
   "source": [
    "Next we’ll convert and upload the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8fc461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_file = \"linear_validation.data\"\n",
    "\n",
    "f = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(f, val_X.astype(\"float32\"), val_y.astype(\"float32\"))\n",
    "f.seek(0)\n",
    "\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"validation\", validation_file)\n",
    ").upload_fileobj(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015c62aa",
   "metadata": {},
   "source": [
    "## Training the linear model\n",
    "Once we have the data preprocessed and available in the correct format for training, the next step is to actually train the model using the data. Since this data is relatively small, it isn't meant to show off the performance of the Linear Learner training algorithm, although we have tested it on multi-terabyte datasets.\n",
    "\n",
    "Again, we'll use the Amazon SageMaker Python SDK to kick off training, and monitor status until it is completed. In this example that takes between 7 and 11 minutes. Despite the dataset being small, provisioning hardware and loading the algorithm container take time upfront.\n",
    "\n",
    "First, let's specify our containers. Since we want this notebook to run in all 4 of Amazon SageMaker's regions, we'll create a small lookup. More details on algorithm containers can be found in AWS documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c14abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "container = image_uris.retrieve(region=boto3.Session().region_name, framework=\"linear-learner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c345251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job name is: BASELINE-linear-2021-07-19-16-49-06\n"
     ]
    }
   ],
   "source": [
    "linear_job = \"BASELINE-linear-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "print(\"Job name is:\", linear_job)\n",
    "\n",
    "linear_training_params = {\n",
    "    \"RoleArn\": role,\n",
    "    \"TrainingJobName\": linear_job,\n",
    "    \"AlgorithmSpecification\": {\"TrainingImage\": container, \"TrainingInputMode\": \"File\"},\n",
    "    \"ResourceConfig\": {\"InstanceCount\": 1, \"InstanceType\": \"ml.c4.2xlarge\", \"VolumeSizeInGB\": 10},\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": \"s3://{}/{}/train/\".format(bucket, prefix),\n",
    "                    \"S3DataDistributionType\": \"ShardedByS3Key\",\n",
    "                }\n",
    "            },\n",
    "            \"CompressionType\": \"None\",\n",
    "            \"RecordWrapperType\": \"None\",\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": \"s3://{}/{}/validation/\".format(bucket, prefix),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                }\n",
    "            },\n",
    "            \"CompressionType\": \"None\",\n",
    "            \"RecordWrapperType\": \"None\",\n",
    "        },\n",
    "    ],\n",
    "    \"OutputDataConfig\": {\"S3OutputPath\": \"s3://{}/{}/\".format(bucket, prefix)},\n",
    "    \"HyperParameters\": {\n",
    "        \"feature_dim\": \"8\",\n",
    "        \"mini_batch_size\": \"100\",\n",
    "        \"predictor_type\": \"regressor\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"num_models\": \"32\",\n",
    "        \"loss\": \"absolute_loss\",\n",
    "    },\n",
    "    \"StoppingCondition\": {\"MaxRuntimeInSeconds\": 60 * 60},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f679e635",
   "metadata": {},
   "source": [
    "Now let’s kick off our training job in SageMaker’s distributed, managed training, using the parameters we just created. Because training is managed, we don’t have to wait for our job to finish to continue, but for this case, let’s use boto3’s ‘training_job_completed_or_stopped’ waiter so we can ensure that the job has been started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0568e15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress\n",
      "CPU times: user 126 ms, sys: 14.4 ms, total: 141 ms\n",
      "Wall time: 4min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "\n",
    "sm.create_training_job(**linear_training_params)\n",
    "\n",
    "status = sm.describe_training_job(TrainingJobName=linear_job)[\"TrainingJobStatus\"]\n",
    "print(status)\n",
    "sm.get_waiter(\"training_job_completed_or_stopped\").wait(TrainingJobName=linear_job)\n",
    "if status == \"Failed\":\n",
    "    message = sm.describe_training_job(TrainingJobName=linear_job)[\"FailureReason\"]\n",
    "    print(\"Training failed with the following error: {}\".format(message))\n",
    "    raise Exception(\"Training job failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e0e269",
   "metadata": {},
   "source": [
    "## Host\n",
    "\n",
    "Now that we’ve trained the linear algorithm on our data, let’s setup a model which can later be hosted. We will: 1. Point to the scoring container 1. Point to the model.tar.gz that came from training 1. Create the hosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a722bade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:405147176623:model/baseline-linear-2021-07-19-16-49-06\n"
     ]
    }
   ],
   "source": [
    "linear_hosting_container = {\n",
    "    \"Image\": container,\n",
    "    \"ModelDataUrl\": sm.describe_training_job(TrainingJobName=linear_job)[\"ModelArtifacts\"][\n",
    "        \"S3ModelArtifacts\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "create_model_response = sm.create_model(\n",
    "    ModelName=linear_job, ExecutionRoleArn=role, PrimaryContainer=linear_hosting_container\n",
    ")\n",
    "\n",
    "print(create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12988de",
   "metadata": {},
   "source": [
    "Once we’ve setup a model, we can configure what our hosting endpoints should be. Here we specify: 1. EC2 instance type to use for hosting 1. Initial number of instances 1. Our hosting model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6738998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION-linear-endpoint-config-2021-07-19-16-53-07\n",
      "Endpoint Config Arn: arn:aws:sagemaker:us-east-1:405147176623:endpoint-config/validation-linear-endpoint-config-2021-07-19-16-53-07\n"
     ]
    }
   ],
   "source": [
    "linear_endpoint_config = \"VALIDATION-linear-endpoint-config-\" + time.strftime(\n",
    "    \"%Y-%m-%d-%H-%M-%S\", time.gmtime()\n",
    ")\n",
    "print(linear_endpoint_config)\n",
    "create_endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName=linear_endpoint_config,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.m4.xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": linear_job,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5a8b6a",
   "metadata": {},
   "source": [
    "Now that we’ve specified how our endpoint should be configured, we can create them. This can be done in the background, but for now let’s run a loop that updates us on the status of the endpoints so that we know when they are ready for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de7eb5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION-linear-endpoint-202107191653\n",
      "arn:aws:sagemaker:us-east-1:405147176623:endpoint/validation-linear-endpoint-202107191653\n",
      "Status: Creating\n",
      "Arn: arn:aws:sagemaker:us-east-1:405147176623:endpoint/validation-linear-endpoint-202107191653\n",
      "Status: InService\n",
      "CPU times: user 197 ms, sys: 4.55 ms, total: 202 ms\n",
      "Wall time: 6min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "linear_endpoint = \"VALIDATION-linear-endpoint-\" + time.strftime(\"%Y%m%d%H%M\", time.gmtime())\n",
    "print(linear_endpoint)\n",
    "create_endpoint_response = sm.create_endpoint(\n",
    "    EndpointName=linear_endpoint, EndpointConfigName=linear_endpoint_config\n",
    ")\n",
    "print(create_endpoint_response[\"EndpointArn\"])\n",
    "\n",
    "resp = sm.describe_endpoint(EndpointName=linear_endpoint)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "sm.get_waiter(\"endpoint_in_service\").wait(EndpointName=linear_endpoint)\n",
    "\n",
    "resp = sm.describe_endpoint(EndpointName=linear_endpoint)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "if status != \"InService\":\n",
    "    raise Exception(\"Endpoint creation did not succeed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5f2e53",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "Now that we have our hosted endpoint, we can generate statistical predictions from it. Let’s predict on our test dataset to understand how accurate our model is.\n",
    "\n",
    "There are many metrics to measure classification accuracy. Common examples include include: - Precision - Recall - F1 measure - Area under the ROC curve - AUC - Total Classification Accuracy - Mean Absolute Error\n",
    "\n",
    "For our example, we’ll keep things simple and use total classification accuracy as our metric of choice. We will also evaluate Mean Absolute Error (MAE) as the linear-learner has been optimized using this metric, not necessarily because it is a relevant metric from an application point of view. We’ll compare the performance of the linear-learner against a naive benchmark prediction which uses majority class observed in the training data set for prediction on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e9d8e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np2csv(arr):\n",
    "    csv = io.BytesIO()\n",
    "    np.savetxt(csv, arr, delimiter=\",\", fmt=\"%g\")\n",
    "    return csv.getvalue().decode().rstrip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96968b38",
   "metadata": {},
   "source": [
    "Next, we’ll invoke the endpoint to get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d24f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = boto3.client(\"runtime.sagemaker\")\n",
    "\n",
    "payload = np2csv(test_X)\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=linear_endpoint, ContentType=\"text/csv\", Body=payload\n",
    ")\n",
    "result = json.loads(response[\"Body\"].read().decode())\n",
    "test_pred = np.array([r[\"score\"] for r in result[\"predictions\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2e068a",
   "metadata": {},
   "source": [
    "Let’s compare linear learner based mean absolute prediction errors from a baseline prediction which uses majority class to predict every instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88c2a456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE Baseline : 0.507\n",
      "Test MAE Linear: 0.793\n"
     ]
    }
   ],
   "source": [
    "test_mae_linear = np.mean(np.abs(test_y - test_pred))\n",
    "test_mae_baseline = np.mean(\n",
    "    np.abs(test_y - np.median(train_y))\n",
    ")  ## training median as baseline predictor\n",
    "\n",
    "print(\"Test MAE Baseline :\", round(test_mae_baseline, 3))\n",
    "print(\"Test MAE Linear:\", round(test_mae_linear, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57de3279",
   "metadata": {},
   "source": [
    "Let’s compare predictive accuracy using a classification threshold of 0.5 for the predicted and compare against the majority class prediction from training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0db8b172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 14.8 %\n",
      "Baseline Accuracy: 49.3 %\n"
     ]
    }
   ],
   "source": [
    "test_pred_class = (test_pred > 0.5) + 0\n",
    "test_pred_baseline = np.repeat(np.median(train_y), len(test_y))\n",
    "\n",
    "prediction_accuracy = np.mean((test_y == test_pred_class)) * 100\n",
    "baseline_accuracy = np.mean((test_y == test_pred_baseline)) * 100\n",
    "\n",
    "print(\"Prediction Accuracy:\", round(prediction_accuracy, 1), \"%\")\n",
    "print(\"Baseline Accuracy:\", round(baseline_accuracy, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1303913",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test_y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60a51ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(test_y, test_pred_class, normalize=True)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c9ed873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.15\n",
      "Recall: 0.15\n",
      "F-Beta: 0.15\n",
      "Support: None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "(precision, recall, fbeta, support) = precision_recall_fscore_support(test_y, test_pred_class, average='micro')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F-Beta: {fbeta:.2f}')\n",
    "print(f'Support: {support}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05998ba0",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b4dfb6",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a425b3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '13a2e1c3-656f-4afb-b7c9-b19e88791b7f',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '13a2e1c3-656f-4afb-b7c9-b19e88791b7f',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Mon, 19 Jul 2021 16:59:40 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.delete_endpoint(EndpointName=linear_endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
